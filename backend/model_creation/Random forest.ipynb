{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-18T03:53:21.076258Z",
     "start_time": "2024-02-18T03:53:19.927535400Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colums: Index(['n_tokens_title', 'n_tokens_content', 'n_unique_tokens',\n",
      "       'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs',\n",
      "       'num_self_hrefs', 'num_imgs', 'num_videos', 'average_token_length',\n",
      "       'num_keywords', 'data_channel_is_lifestyle',\n",
      "       'data_channel_is_entertainment', 'data_channel_is_bus',\n",
      "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
      "       'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min',\n",
      "       'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg',\n",
      "       'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares',\n",
      "       'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday',\n",
      "       'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday',\n",
      "       'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00',\n",
      "       'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
      "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
      "       'global_rate_negative_words', 'rate_positive_words',\n",
      "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
      "       'max_positive_polarity', 'avg_negative_polarity',\n",
      "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
      "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
      "       'abs_title_sentiment_polarity'],\n",
      "      dtype='object')\n",
      "features: ['n_tokens_title', 'n_tokens_content', 'n_unique_tokens', 'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs', 'num_imgs', 'num_videos', 'average_token_length', 'weekday_is_monday', 'weekday_is_tuesday', 'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday', 'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'global_subjectivity', 'global_sentiment_polarity', 'global_rate_positive_words', 'global_rate_negative_words', 'rate_positive_words', 'rate_negative_words', 'avg_positive_polarity', 'max_positive_polarity', 'avg_negative_polarity', 'min_negative_polarity', 'title_subjectivity', 'title_sentiment_polarity', 'abs_title_sentiment_polarity', 'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "(19821, 35)\n",
      "(11894, 35)\n",
      "(7929, 35)\n",
      "targets: [[-0.14581653]\n",
      " [-0.15441734]\n",
      " [ 0.11220795]\n",
      " ...\n",
      " [ 0.09500632]\n",
      " [-0.25023043]\n",
      " [-0.1888206 ]]\n",
      "data: [[-1.60772590e+00 -4.74451259e-01  1.78983723e-03 ...  4.34559779e-01\n",
      "  -6.72771916e-01  5.75050509e-01]\n",
      " [ 1.23048186e+00  9.19437671e+00 -7.39034343e-02 ...  1.39679341e+00\n",
      "  -6.90038498e-01 -8.83876839e-02]\n",
      " [ 7.57447233e-01 -3.51335557e-01  3.25676620e-03 ... -6.48338607e-01\n",
      "  -6.44938232e-01 -6.94015739e-01]\n",
      " ...\n",
      " [ 1.23048186e+00 -7.27050716e-01  2.79063632e-02 ... -6.24922259e-01\n",
      "  -6.13740515e-01 -6.69708780e-01]\n",
      " [ 2.84412606e-01  3.28703405e-02 -9.31336282e-03 ...  2.06860629e+00\n",
      "  -5.88675760e-01 -6.36253940e-01]\n",
      " [-1.88622020e-01 -6.59124812e-01  1.32395104e-02 ...  2.30502359e+00\n",
      "  -6.45136837e-01 -6.94012953e-01]]\n",
      "colums: Index(['n_tokens_title', 'n_tokens_content', 'n_unique_tokens',\n",
      "       'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs',\n",
      "       'num_self_hrefs', 'num_imgs', 'num_videos', 'average_token_length',\n",
      "       'num_keywords', 'data_channel_is_lifestyle',\n",
      "       'data_channel_is_entertainment', 'data_channel_is_bus',\n",
      "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
      "       'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min',\n",
      "       'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg',\n",
      "       'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares',\n",
      "       'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday',\n",
      "       'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday',\n",
      "       'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00',\n",
      "       'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
      "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
      "       'global_rate_negative_words', 'rate_positive_words',\n",
      "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
      "       'max_positive_polarity', 'avg_negative_polarity',\n",
      "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
      "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
      "       'abs_title_sentiment_polarity'],\n",
      "      dtype='object')\n",
      "features: ['n_tokens_title', 'n_tokens_content', 'n_unique_tokens', 'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs', 'num_imgs', 'num_videos', 'average_token_length', 'weekday_is_monday', 'weekday_is_tuesday', 'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday', 'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'global_subjectivity', 'global_sentiment_polarity', 'global_rate_positive_words', 'global_rate_negative_words', 'rate_positive_words', 'rate_negative_words', 'avg_positive_polarity', 'max_positive_polarity', 'avg_negative_polarity', 'min_negative_polarity', 'title_subjectivity', 'title_sentiment_polarity', 'abs_title_sentiment_polarity', 'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "%run preprocess.ipynb\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_processed_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T03:53:26.735926800Z",
     "start_time": "2024-02-18T03:53:21.079256300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 332, 'name': 'Online News Popularity', 'repository_url': 'https://archive.ics.uci.edu/dataset/332/online+news+popularity', 'data_url': 'https://archive.ics.uci.edu/static/public/332/data.csv', 'abstract': 'This dataset summarizes a heterogeneous set of features about articles published by Mashable in a period of two years. The goal is to predict the number of shares in social networks (popularity).', 'area': 'Business', 'tasks': ['Classification', 'Regression'], 'characteristics': ['Multivariate'], 'num_instances': 39797, 'num_features': 58, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': [' shares'], 'index_col': ['url'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2015, 'last_updated': 'Thu Feb 15 2024', 'dataset_doi': '10.24432/C5NS3V', 'creators': ['Kelwin Fernandes', 'Pedro Vinagre', 'Paulo Cortez', 'Pedro Sernadela'], 'intro_paper': {'title': 'A Proactive Intelligent Decision Support System for Predicting the Popularity of Online News', 'authors': 'Kelwin Fernandes, Pedro Vinagre, P. Cortez', 'published_in': 'Portuguese Conference on Artificial Intelligence', 'year': 2015, 'url': 'https://www.semanticscholar.org/paper/A-Proactive-Intelligent-Decision-Support-System-for-Fernandes-Vinagre/ad7f3da7a5d6a1e18cc5a176f18f52687b912fea', 'doi': None}, 'additional_info': {'summary': '* The articles were published by Mashable (www.mashable.com) and their content as the rights to reproduce it belongs to them. Hence, this dataset does not share the original content but some statistics associated with it. The original content be publicly accessed and retrieved using the provided urls.\\r\\n* Acquisition date: January 8, 2015\\r\\n* The estimated relative performance values were estimated by the authors using a Random Forest classifier and a rolling windows as assessment method.  See their article for more details on how the relative performance values were set.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': \"Number of Attributes: 61 (58 predictive attributes, 2 non-predictive, 1 goal field)\\r\\n\\r\\nAttribute Information:\\r\\n     0. url:                           URL of the article (non-predictive)\\r\\n     1. timedelta:                     Days between the article publication and the dataset acquisition (non-predictive)\\r\\n     2. n_tokens_title:                Number of words in the title\\r\\n     3. n_tokens_content:              Number of words in the content\\r\\n     4. n_unique_tokens:               Rate of unique words in the content\\r\\n     5. n_non_stop_words:              Rate of non-stop words in the content\\r\\n     6. n_non_stop_unique_tokens:      Rate of unique non-stop words in the content\\r\\n     7. num_hrefs:                     Number of links\\r\\n     8. num_self_hrefs:                Number of links to other articles published by Mashable\\r\\n     9. num_imgs:                      Number of images\\r\\n    10. num_videos:                    Number of videos\\r\\n    11. average_token_length:          Average length of the words in the content\\r\\n    12. num_keywords:                  Number of keywords in the metadata\\r\\n    13. data_channel_is_lifestyle:     Is data channel 'Lifestyle'?\\r\\n    14. data_channel_is_entertainment: Is data channel 'Entertainment'?\\r\\n    15. data_channel_is_bus:           Is data channel 'Business'?\\r\\n    16. data_channel_is_socmed:        Is data channel 'Social Media'?\\r\\n    17. data_channel_is_tech:          Is data channel 'Tech'?\\r\\n    18. data_channel_is_world:         Is data channel 'World'?\\r\\n    19. kw_min_min:                    Worst keyword (min. shares)\\r\\n    20. kw_max_min:                    Worst keyword (max. shares)\\r\\n    21. kw_avg_min:                    Worst keyword (avg. shares)\\r\\n    22. kw_min_max:                    Best keyword (min. shares)\\r\\n    23. kw_max_max:                    Best keyword (max. shares)\\r\\n    24. kw_avg_max:                    Best keyword (avg. shares)\\r\\n    25. kw_min_avg:                    Avg. keyword (min. shares)\\r\\n    26. kw_max_avg:                    Avg. keyword (max. shares)\\r\\n    27. kw_avg_avg:                    Avg. keyword (avg. shares)\\r\\n    28. self_reference_min_shares:     Min. shares of referenced articles in Mashable\\r\\n    29. self_reference_max_shares:     Max. shares of referenced articles in Mashable\\r\\n    30. self_reference_avg_sharess:    Avg. shares of referenced articles in Mashable\\r\\n    31. weekday_is_monday:             Was the article published on a Monday?\\r\\n    32. weekday_is_tuesday:            Was the article published on a Tuesday?\\r\\n    33. weekday_is_wednesday:          Was the article published on a Wednesday?\\r\\n    34. weekday_is_thursday:           Was the article published on a Thursday?\\r\\n    35. weekday_is_friday:             Was the article published on a Friday?\\r\\n    36. weekday_is_saturday:           Was the article published on a Saturday?\\r\\n    37. weekday_is_sunday:             Was the article published on a Sunday?\\r\\n    38. is_weekend:                    Was the article published on the weekend?\\r\\n    39. LDA_00:                        Closeness to LDA topic 0\\r\\n    40. LDA_01:                        Closeness to LDA topic 1\\r\\n    41. LDA_02:                        Closeness to LDA topic 2\\r\\n    42. LDA_03:                        Closeness to LDA topic 3\\r\\n    43. LDA_04:                        Closeness to LDA topic 4\\r\\n    44. global_subjectivity:           Text subjectivity\\r\\n    45. global_sentiment_polarity:     Text sentiment polarity\\r\\n    46. global_rate_positive_words:    Rate of positive words in the content\\r\\n    47. global_rate_negative_words:    Rate of negative words in the content\\r\\n    48. rate_positive_words:           Rate of positive words among non-neutral tokens\\r\\n    49. rate_negative_words:           Rate of negative words among non-neutral tokens\\r\\n    50. avg_positive_polarity:         Avg. polarity of positive words\\r\\n    51. min_positive_polarity:         Min. polarity of positive words\\r\\n    52. max_positive_polarity:         Max. polarity of positive words\\r\\n    53. avg_negative_polarity:         Avg. polarity of negative  words\\r\\n    54. min_negative_polarity:         Min. polarity of negative  words\\r\\n    55. max_negative_polarity:         Max. polarity of negative  words\\r\\n    56. title_subjectivity:            Title subjectivity\\r\\n    57. title_sentiment_polarity:      Title polarity\\r\\n    58. abs_title_subjectivity:        Absolute subjectivity level\\r\\n    59. abs_title_sentiment_polarity:  Absolute polarity level\\r\\n    60. shares:                        Number of shares (target)\", 'citation': None}}\n",
      "                             name     role         type demographic  \\\n",
      "0                             url       ID  Categorical        None   \n",
      "1                       timedelta    Other   Continuous        None   \n",
      "2                  n_tokens_title  Feature   Continuous        None   \n",
      "3                n_tokens_content  Feature   Continuous        None   \n",
      "4                 n_unique_tokens  Feature   Continuous        None   \n",
      "..                            ...      ...          ...         ...   \n",
      "56             title_subjectivity  Feature   Continuous        None   \n",
      "57       title_sentiment_polarity  Feature   Continuous        None   \n",
      "58         abs_title_subjectivity  Feature   Continuous        None   \n",
      "59   abs_title_sentiment_polarity  Feature   Continuous        None   \n",
      "60                         shares   Target      Integer        None   \n",
      "\n",
      "   description units missing_values  \n",
      "0         None  None             no  \n",
      "1         None  None             no  \n",
      "2         None  None             no  \n",
      "3         None  None             no  \n",
      "4         None  None             no  \n",
      "..         ...   ...            ...  \n",
      "56        None  None             no  \n",
      "57        None  None             no  \n",
      "58        None  None             no  \n",
      "59        None  None             no  \n",
      "60        None  None             no  \n",
      "\n",
      "[61 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# load data without preprocessing\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "online_news_popularity = fetch_ucirepo(id=332)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X_raw = online_news_popularity.data.features\n",
    "y_raw = online_news_popularity.data.targets\n",
    "\n",
    "# metadata\n",
    "print(online_news_popularity.metadata)\n",
    "# variable information\n",
    "print(online_news_popularity.variables)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T03:53:31.437708300Z",
     "start_time": "2024-02-18T03:53:26.739923900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# split unpreprocessed data into training, validation and test sets\n",
    "X_train_raw, y_train_raw, X_val_raw, y_val_raw, X_test_raw, y_test_raw = split(X_raw, y_raw,test_size=0.2, val_size=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T03:53:31.468782900Z",
     "start_time": "2024-02-18T03:53:31.439723900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodcs\\.conda\\envs\\data_science_tests\\Lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\rodcs\\.conda\\envs\\data_science_tests\\Lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomForestRegressor(n_estimators=72, random_state=42)",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=72, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=72, random_state=42)</pre></div></div></div></div></div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random forest regressor model\n",
    "rf = RandomForestRegressor(n_estimators=72, random_state=42) # n_estimators is the number of trees in the forest\n",
    "rf.fit(X_train, y_train)\n",
    "# create a random forest regressor model\n",
    "rf_raw = RandomForestRegressor(n_estimators=72, random_state=42) # n_estimators is the number of trees in the forest\n",
    "rf.fit(X_train_raw, y_train_raw)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T03:59:13.674496800Z",
     "start_time": "2024-02-18T03:53:31.473766500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodcs\\.conda\\envs\\data_science_tests\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 35 features, but RandomForestRegressor is expecting 58 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Caclulate performance using the validation set\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mean_squared_error, mean_absolute_error\n\u001B[1;32m----> 3\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mrf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m mse \u001B[38;5;241m=\u001B[39m mean_squared_error(y_val, y_pred)\n\u001B[0;32m      5\u001B[0m mae \u001B[38;5;241m=\u001B[39m mean_absolute_error(y_val, y_pred)\n",
      "File \u001B[1;32m~\\.conda\\envs\\data_science_tests\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:984\u001B[0m, in \u001B[0;36mForestRegressor.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    982\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    983\u001B[0m \u001B[38;5;66;03m# Check data\u001B[39;00m\n\u001B[1;32m--> 984\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_X_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    986\u001B[0m \u001B[38;5;66;03m# Assign chunk of trees to jobs\u001B[39;00m\n\u001B[0;32m    987\u001B[0m n_jobs, _, _ \u001B[38;5;241m=\u001B[39m _partition_estimators(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_estimators, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\data_science_tests\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:599\u001B[0m, in \u001B[0;36mBaseForest._validate_X_predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    596\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    597\u001B[0m \u001B[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001B[39;00m\n\u001B[0;32m    598\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 599\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    600\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(X) \u001B[38;5;129;01mand\u001B[39;00m (X\u001B[38;5;241m.\u001B[39mindices\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc \u001B[38;5;129;01mor\u001B[39;00m X\u001B[38;5;241m.\u001B[39mindptr\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc):\n\u001B[0;32m    601\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo support for np.int64 index based sparse matrices\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\data_science_tests\\Lib\\site-packages\\sklearn\\base.py:626\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    623\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m--> 626\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_n_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\.conda\\envs\\data_science_tests\\Lib\\site-packages\\sklearn\\base.py:415\u001B[0m, in \u001B[0;36mBaseEstimator._check_n_features\u001B[1;34m(self, X, reset)\u001B[0m\n\u001B[0;32m    412\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m    414\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_:\n\u001B[1;32m--> 415\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    416\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    417\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    418\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: X has 35 features, but RandomForestRegressor is expecting 58 features as input."
     ]
    }
   ],
   "source": [
    "# Caclulate performance using the validation set\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "y_pred = rf.predict(X_val)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T03:59:14.140906500Z",
     "start_time": "2024-02-18T03:59:13.674496800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tune hyperparameters\n",
    "def grid_search_tunning(n_estimators, criterion, max_depth, min_samples_split, X_train, y_train, X_val, y_val):\n",
    "    best_mse = float('inf')\n",
    "    best_params = {}\n",
    "    for n in n_estimators:\n",
    "        for c in criterion:\n",
    "            for d in max_depth:\n",
    "                for s in min_samples_split:\n",
    "                    rf = RandomForestRegressor(n_estimators=n, criterion=c, max_depth=d, min_samples_split=s, random_state=42)\n",
    "                    rf.fit(X_train, y_train)\n",
    "                    y_pred = rf.predict(X_val)\n",
    "                    mse = mean_squared_error(y_val, y_pred)\n",
    "                    if mse < best_mse:\n",
    "                        best_mse = mse\n",
    "                        best_params = {'n_estimators': n, 'criterion': c, 'max_depth': d, 'min_samples_split': s}\n",
    "    return best_mse, best_params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_search_tunning(n_estimators=[100],\n",
    "                    criterion=[\"squared_error\", \"friedman_mse\", \"absolute_error\"],\n",
    "                    max_depth=[None, 2, 5, 10, 20, 30, 40],\n",
    "                    min_samples_split=[2, 5, 10, 20],\n",
    "                    X_train=X_train, y_train=y_train,\n",
    "                    X_val=X_val,\n",
    "                    y_val=y_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
