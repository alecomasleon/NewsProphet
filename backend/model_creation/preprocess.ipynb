{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use these functions in another file, add the following:\n",
    "%run preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T02:55:21.635184500Z",
     "start_time": "2024-02-18T02:55:20.451645Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.9/site-packages/')\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T02:55:27.585295900Z",
     "start_time": "2024-02-18T02:55:21.640184800Z"
    }
   },
   "outputs": [],
   "source": [
    "online_news_popularity = fetch_ucirepo(id=332)\n",
    "X = online_news_popularity.data.features\n",
    "y = online_news_popularity.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T02:55:27.630107700Z",
     "start_time": "2024-02-18T02:55:27.591282600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n0            12.0             219.0         0.663594               1.0   \n1             9.0             255.0         0.604743               1.0   \n2             9.0             211.0         0.575130               1.0   \n3             9.0             531.0         0.503788               1.0   \n4            13.0            1072.0         0.415646               1.0   \n\n   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  num_videos  \\\n0                  0.815385        4.0             2.0       1.0         0.0   \n1                  0.791946        3.0             1.0       1.0         0.0   \n2                  0.663866        3.0             1.0       1.0         0.0   \n3                  0.665635        9.0             0.0       1.0         0.0   \n4                  0.540890       19.0            19.0      20.0         0.0   \n\n   average_token_length  ...  avg_positive_polarity  min_positive_polarity  \\\n0              4.680365  ...               0.378636               0.100000   \n1              4.913725  ...               0.286915               0.033333   \n2              4.393365  ...               0.495833               0.100000   \n3              4.404896  ...               0.385965               0.136364   \n4              4.682836  ...               0.411127               0.033333   \n\n   max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n0                    0.7              -0.350000                 -0.600   \n1                    0.7              -0.118750                 -0.125   \n2                    1.0              -0.466667                 -0.800   \n3                    0.8              -0.369697                 -0.600   \n4                    1.0              -0.220192                 -0.500   \n\n   max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n0              -0.200000            0.500000                 -0.187500   \n1              -0.100000            0.000000                  0.000000   \n2              -0.133333            0.000000                  0.000000   \n3              -0.166667            0.000000                  0.000000   \n4              -0.050000            0.454545                  0.136364   \n\n   abs_title_subjectivity  abs_title_sentiment_polarity  \n0                0.000000                      0.187500  \n1                0.500000                      0.000000  \n2                0.500000                      0.000000  \n3                0.500000                      0.000000  \n4                0.045455                      0.136364  \n\n[5 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_tokens_title</th>\n      <th>n_tokens_content</th>\n      <th>n_unique_tokens</th>\n      <th>n_non_stop_words</th>\n      <th>n_non_stop_unique_tokens</th>\n      <th>num_hrefs</th>\n      <th>num_self_hrefs</th>\n      <th>num_imgs</th>\n      <th>num_videos</th>\n      <th>average_token_length</th>\n      <th>...</th>\n      <th>avg_positive_polarity</th>\n      <th>min_positive_polarity</th>\n      <th>max_positive_polarity</th>\n      <th>avg_negative_polarity</th>\n      <th>min_negative_polarity</th>\n      <th>max_negative_polarity</th>\n      <th>title_subjectivity</th>\n      <th>title_sentiment_polarity</th>\n      <th>abs_title_subjectivity</th>\n      <th>abs_title_sentiment_polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12.0</td>\n      <td>219.0</td>\n      <td>0.663594</td>\n      <td>1.0</td>\n      <td>0.815385</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.680365</td>\n      <td>...</td>\n      <td>0.378636</td>\n      <td>0.100000</td>\n      <td>0.7</td>\n      <td>-0.350000</td>\n      <td>-0.600</td>\n      <td>-0.200000</td>\n      <td>0.500000</td>\n      <td>-0.187500</td>\n      <td>0.000000</td>\n      <td>0.187500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.0</td>\n      <td>255.0</td>\n      <td>0.604743</td>\n      <td>1.0</td>\n      <td>0.791946</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.913725</td>\n      <td>...</td>\n      <td>0.286915</td>\n      <td>0.033333</td>\n      <td>0.7</td>\n      <td>-0.118750</td>\n      <td>-0.125</td>\n      <td>-0.100000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9.0</td>\n      <td>211.0</td>\n      <td>0.575130</td>\n      <td>1.0</td>\n      <td>0.663866</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.393365</td>\n      <td>...</td>\n      <td>0.495833</td>\n      <td>0.100000</td>\n      <td>1.0</td>\n      <td>-0.466667</td>\n      <td>-0.800</td>\n      <td>-0.133333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.0</td>\n      <td>531.0</td>\n      <td>0.503788</td>\n      <td>1.0</td>\n      <td>0.665635</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.404896</td>\n      <td>...</td>\n      <td>0.385965</td>\n      <td>0.136364</td>\n      <td>0.8</td>\n      <td>-0.369697</td>\n      <td>-0.600</td>\n      <td>-0.166667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.0</td>\n      <td>1072.0</td>\n      <td>0.415646</td>\n      <td>1.0</td>\n      <td>0.540890</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>4.682836</td>\n      <td>...</td>\n      <td>0.411127</td>\n      <td>0.033333</td>\n      <td>1.0</td>\n      <td>-0.220192</td>\n      <td>-0.500</td>\n      <td>-0.050000</td>\n      <td>0.454545</td>\n      <td>0.136364</td>\n      <td>0.045455</td>\n      <td>0.136364</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 58 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T02:55:27.631049900Z",
     "start_time": "2024-02-18T02:55:27.614319300Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_raw_data():\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T02:55:27.631560400Z",
     "start_time": "2024-02-18T02:55:27.619486200Z"
    }
   },
   "outputs": [],
   "source": [
    "# We're going to need this function when we process an article to input to the model\n",
    "def get_scaler(df):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df)\n",
    "\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T02:55:27.631560400Z",
     "start_time": "2024-02-18T02:55:27.625589100Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_one(df, verbose=False):\n",
    "    print(type(df))\n",
    "    columns = df.columns\n",
    "    scaler = get_scaler(df)\n",
    "    if verbose:\n",
    "        print('before:')\n",
    "        print(df.mean(axis=0))\n",
    "    df = scaler.transform(df)\n",
    "    if verbose:\n",
    "        print('after:')\n",
    "        print(df.mean(axis=0))\n",
    "    print(type(df))\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T02:55:27.686611100Z",
     "start_time": "2024-02-18T02:55:27.631049900Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(X, y, verbose=False):\n",
    "    X = normalize_one(X, verbose)\n",
    "    y = normalize_one(y, verbose)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T02:55:27.695795300Z",
     "start_time": "2024-02-18T02:55:27.636864900Z"
    }
   },
   "outputs": [],
   "source": [
    "def split(X, y, test_size, val_size):\n",
    "    # first we split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=1)\n",
    "    # then we split the training set into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size/(1-test_size), random_state=1)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T03:09:33.455227900Z",
     "start_time": "2024-02-18T03:09:33.447743500Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_processed_data(test_size=0.1, val_size=0.1, verbose=False):\n",
    "    X, y = get_raw_data()\n",
    "    columns = [x.strip() for x in X.columns]\n",
    "    X.columns = columns\n",
    "    X, y = filter_features(X, y, ['n_tokens_title', 'n_tokens_content', 'n_unique_tokens',\n",
    "       'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs', 'num_imgs',\n",
    "       'num_videos', 'average_token_length', 'weekday_is_monday',\n",
    "       'weekday_is_tuesday', 'weekday_is_wednesday', 'weekday_is_thursday',\n",
    "       'weekday_is_friday', 'weekday_is_saturday', 'weekday_is_sunday',\n",
    "       'is_weekend', 'global_subjectivity', 'global_sentiment_polarity',\n",
    "       'global_rate_positive_words', 'global_rate_negative_words',\n",
    "       'rate_positive_words', 'rate_negative_words', 'avg_positive_polarity',\n",
    "       'max_positive_polarity', 'avg_negative_polarity',\n",
    "       'min_negative_polarity', 'title_subjectivity',\n",
    "       'title_sentiment_polarity', 'abs_title_sentiment_polarity', \"LDA_00\", \"LDA_01\", \"LDA_02\", \"LDA_03\", \"LDA_04\"])\n",
    "    X, y = normalize(X, y, verbose)\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = split(X, y, test_size, val_size)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def filter_features(X, y, features):\n",
    "    print(f\"colums: {X.columns}\")\n",
    "    print(f\"features: {features}\")\n",
    "    X = X[features]\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T03:09:35.228000400Z",
     "start_time": "2024-02-18T03:09:35.220449600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T03:09:36.708175Z",
     "start_time": "2024-02-18T03:09:36.661822700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colums: Index(['n_tokens_title', 'n_tokens_content', 'n_unique_tokens',\n",
      "       'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs',\n",
      "       'num_self_hrefs', 'num_imgs', 'num_videos', 'average_token_length',\n",
      "       'num_keywords', 'data_channel_is_lifestyle',\n",
      "       'data_channel_is_entertainment', 'data_channel_is_bus',\n",
      "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
      "       'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min',\n",
      "       'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg',\n",
      "       'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares',\n",
      "       'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday',\n",
      "       'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday',\n",
      "       'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00',\n",
      "       'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
      "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
      "       'global_rate_negative_words', 'rate_positive_words',\n",
      "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
      "       'max_positive_polarity', 'avg_negative_polarity',\n",
      "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
      "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
      "       'abs_title_sentiment_polarity'],\n",
      "      dtype='object')\n",
      "features: ['n_tokens_title', 'n_tokens_content', 'n_unique_tokens', 'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs', 'num_imgs', 'num_videos', 'average_token_length', 'weekday_is_monday', 'weekday_is_tuesday', 'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday', 'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'global_subjectivity', 'global_sentiment_polarity', 'global_rate_positive_words', 'global_rate_negative_words', 'rate_positive_words', 'rate_negative_words', 'avg_positive_polarity', 'max_positive_polarity', 'avg_negative_polarity', 'min_negative_polarity', 'title_subjectivity', 'title_sentiment_polarity', 'abs_title_sentiment_polarity', 'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "(19821, 35)\n",
      "(11894, 35)\n",
      "(7929, 35)\n",
      "targets: [[-0.14581653]\n",
      " [-0.15441734]\n",
      " [ 0.11220795]\n",
      " ...\n",
      " [ 0.09500632]\n",
      " [-0.25023043]\n",
      " [-0.1888206 ]]\n",
      "data: [[-1.60772590e+00 -4.74451259e-01  1.78983723e-03 ...  4.34559779e-01\n",
      "  -6.72771916e-01  5.75050509e-01]\n",
      " [ 1.23048186e+00  9.19437671e+00 -7.39034343e-02 ...  1.39679341e+00\n",
      "  -6.90038498e-01 -8.83876839e-02]\n",
      " [ 7.57447233e-01 -3.51335557e-01  3.25676620e-03 ... -6.48338607e-01\n",
      "  -6.44938232e-01 -6.94015739e-01]\n",
      " ...\n",
      " [ 1.23048186e+00 -7.27050716e-01  2.79063632e-02 ... -6.24922259e-01\n",
      "  -6.13740515e-01 -6.69708780e-01]\n",
      " [ 2.84412606e-01  3.28703405e-02 -9.31336282e-03 ...  2.06860629e+00\n",
      "  -5.88675760e-01 -6.36253940e-01]\n",
      " [-1.88622020e-01 -6.59124812e-01  1.32395104e-02 ...  2.30502359e+00\n",
      "  -6.45136837e-01 -6.94012953e-01]]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = get_processed_data(test_size=0.2, val_size=0.3)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(f\"targets: {y_train}\")\n",
    "print(f\"data: {X_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-18T02:55:27.659425900Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
